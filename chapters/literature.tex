
\chapter{بررسی پژوهش‌های پیشین:}\label{chap:litr}

این فصل به بررسی پژوهش‌های موجود مرتبط با \lr{\tt{MEC}} در نسل چهارم صنعت، مجازی‌سازی در \lr{\tt{MEC}} و رقابت بر سر منابع سخت‌افزاری در محیط‌های ابری و لبه‌ شبکه می‌پردازد. همچنین رویکردهای پیشین برای اندازه‌گیری تداخل (چه کیفی و چه کمّی)، تحلیل رقابت در میان منابع سخت‌افزاری، و راهبردهای موجود برای کاهش تداخل را مرور می‌کند. این بحث محدودیت‌های پژوهش‌های کنونی را برجسته ساخته و مسیر پیشنهادی این رساله را توجیه می‌کند.

\section{پردازش لبه در نسل چهارم صنعت}

پردازش لبه در محیط‌های نسل چهارم صنعت و اینترنت اشیاء صنعتی توجه چشمگیری را به خود جلب کرده است، زیرا امکان پردازش در محل را با تأخیر پایین فراهم می‌کند و وابستگی به زیرساخت‌های ابری را کاهش می‌دهد. در طرح‌های اینترنت اشیا صنعتی که با استقرار گسترده حسگرها، حجم بالای داده و محدودیت‌های سختگیرانه بلادرنگ شناخته می‌شوند، معماری پردازش لبه شبکه به حل چالش‌های ازدحام شبکه، تأخیر و مقیاس‌پذیری کمک می‌کنند. در این بخش به‌طور نظام‌مند کاربردهای پردازش لبه شبکه در اینترنت صنعتی اشیا و نسل چهارم صنعت را بررسی کرده و آن‌ها را بر اساس اهداف کلیدی همچون تأخیر، امنیت، بهره‌برداری از منابع و بهره‌وری انرژی دسته‌بندی می‌کنیم. در این مطالعه اصطلاحات مه \lr{\tt{Fog}} و لبه \lr{\tt{Edge}} به‌صورت جایگزین یکدیگر به کار می‌روند، زیرا هر دو از دیدگاه اهداف تجاری در پی دستیابی به نتایج مشابه هستند. برای تحقیقات رویکرد گلوله برفی\LTRfootnote{Snowballing} با جستجوی پایگاه داده\LTRfootnote{database} ترکیب شده است. کلیدواژه‌هایی که به عنوان نقطه شروع جستجو تعیین شدند، \lr{\tt{Edge}}، \lr{\tt{Fog}}، \lr{\tt{Computing}}، \lr{\tt{Industrial}} و \lr{\tt{IoT}} هستند. پایگاه‌های داده \lr{\tt{Science Direct}} و \lr{\tt{IEEE Explore}} برای جستجو انتخاب شدند.

\subsection{تاخیر}

تأخیر یک نگرانی رایج در میان کاربردهای پردازش لبه شبکه است. در یک آزمایش مربوط به تشخیص چهره \cite{yi2015fog} نشان داده شده است که انتقال برنامه کاربردی از ابر به لبه شبکه، زمان پاسخ را از ۹۰۰ میلی‌ثانیه به ۱۶۰ میلی‌ثانیه کاهش می‌دهد. با کاهش تأخیر، سرورهای لبه می‌توانند به پایش و کنترل فرآیندها \cite{li2018deep} یا وضعیت ماشین‌ها \cite{bose2019adepos} کمک کنند و پیش‌بینی‌هایی در شرایط عدم قطعیت انجام دهند \cite{taik2020electrical}. برای مدیریت مؤثر سکوی\LTRfootnote{Platform} اینترنت اشیاء صنعتی، راهکارهایی وجود دارد که انعطاف‌پذیری، مقیاس‌پذیری و در دسترس بودن سرورهای لبه شبکه را افزایش می‌دهند و به عنوان اهداف بهره‌برداری از منابع مطرح می‌شوند. یک سیستم کنترل فرآیند تولید در \cite{wu2017fog} پیشنهاد شده است تا خطوط تولید را پایش کرده و داده‌ها را جمع‌آوری و تحلیل کند تا بهره‌وری افزایش یابد. جریان داده‌ی حسگرها از طریق مبدل‌های ارتباطی جمع‌آوری شده و سرور لبه شبکه، با ارسال داده‌ها به‌صورت بلادرنگ، سیگنال‌های کنترلی را فراهم می‌کند. یک معماری متن‌باز\LTRfootnote{Open source} برای شبکه‌های صنعتی در \cite{vakili2019open} همراه با مطالعه‌های موردی در یک محیط شبیه‌سازی‌شده ایستگاه تنظیم گاز پیشنهاد شده است تا پردازش بلادرنگ را برآورده کند.

\subsection{امنیت}

استفاده از دستگاه‌های ناهمگون\LTRfootnote{Heterogeneous} با توانایی محاسباتی کمتر در لبه شبکه، آسیب‌پذیری‌هایی را در زمینه حریم خصوصی و امنیت شبکه ایجاد می‌کند \cite{wu2021blockchain}، که این موضوع دومین هدفی است که در مقالات این حوزه مورد توجه قرار گرفته است. در \cite{chekired2018industrial} یک معماری شبکه هوشمند مبتنی بر محاسبات لبه شبکه پیشنهاد شده است، که در آن تعادل بار داده‌ها با تأخیر کم و امنیت افزایش‌یافته قابل دستیابی است. در \cite{fu2018secure} یک چارچوب پردازش داده پیشنهاد شده است که امکان ذخیره‌سازی امن داده‌ها با استفاده از لبه در سامانه‌های \lr{\tt{IIoT}} را فراهم می‌کند. چالش‌های مدیریت داده و رمزنگاری خلاصه شده و راه‌حل‌های پیشنهادی با استفاده از شبیه‌سازی‌ها در یک نمونه اولیه برای پایش دما در یک کارخانه ارزیابی شده‌اند.

\subsection{بهره‌وری انرژی}

بهره‌وری انرژی یک جنبه حیاتی در معماری‌های لبه شبکه است که هنگام استفاده از سرورهای لبه شبکه باید مد نظر قرار گیرد. \cite{djemame2021energy} یک معماری فنی پیشنهاد می‌کند که از شبکه مبتنی بر نرم‌افزار (\lr{\tt{SDN}})\LTRfootnote{Software Defined Network (SDN)} همراه با مجازی‌سازی عملکرد شبکه (\lr{\tt{NFV}}) \LTRfootnote{Network Function Virtualization (NFV)} و معماری‌های بدون سرور\LTRfootnote{Serverless} برای کاهش مصرف بالای انرژی در لبه شبکه استفاده می‌کند. الگوریتم انتقال داده تطبیقی با استفاده از شبکه مبتنی بر نرم‌افزار در محاسبات لبه برای \lr{\tt{IIoT}} در \cite{li2018adaptive} پیشنهاد شده است تا مسیر بهینه برای بار ترافیکی، مهلت‌های کاربار و مصرف انرژی را پیدا کند. \cite{chalapathi2021iioT} یک معماری برای کاهش تأخیر و افزایش بهره‌وری انرژی در تولید پیشنهاد می‌کند که از شبکه مبتنی بر نرم‌افزار استفاده می‌کند. در این معماری پیشنهادی، حوزه برنامه‌های کاربردی، خدمات نظارت و کنترل ارائه می‌دهد؛ حوزه داده، خدمات پاک‌سازی داده و استخراج ویژگی‌ها با استفاده از \lr{\tt{Hadoop}} را فراهم می‌کند؛ و حوزه شبکه، از شبکه مبتنی بر نرم‌افزار و شبکه حساس به زمان (\lr{\tt{TSN}})\LTRfootnote{Time Sensitive Networks (TSN)} بهره می‌برد. شبکه گسترده کم‌مصرف (\lr{\tt{LoRA}})\LTRfootnote{Low Power Wide Area Network} داده‌ها را از حسگرها دریافت کرده، سپس به یک سرور لبه شبکه که \lr{\tt{Kubernetes}} روی \lr{\tt{Raspberry Pi}} نصب شده است، ارسال می‌کند تا نهایتاً داده‌ها به‌صورت یکپارچه به مرکز داده تحویل داده شوند.

\subsection{یادگیری عمیق}

استفاده از یادگیری عمیق\LTRfootnote{Deep learning} به توان پردازشی و پهنای باند بالایی نیاز دارد. در یک معماری پردازش لبه‌ شبکه که برای یادگیری عمیق طراحی شده است \cite{liang2020edge}، میزان پیچیدگی متناسب با ظرفیت پردازشی سرور‌های لبه‌ شبکه بهینه‌سازی شده است. برای ارزیابی این راهکار، نویسندگان یک شبکه عصبی کانولوشنی (\lr{\tt{CNN}})\LTRfootnote{Convolutional Neural Network (CNN)} با استفاده از داده‌های واقعی اینترنت اشیای صنعتی ایجاد کردند. آن‌ها آزمایش‌هایی انجام دادند که ضمن کاهش ترافیک شبکه، دقت طبقه‌بندی\LTRfootnote{Classification} مدل را حفظ می‌کند. در \cite{pop2021fora} یک معماری مرجع برای سکوی محاسبات مه برای کاربردهای \lr{\tt{IIoT}} پیشنهاد شده است که هر دستگاه با بسته‌هایی دارای برچسب‌ توسط سامانه‌ای با قابلیت خواندن برچسب و با دسترسی به پایگاه داده، آن‌ها را به مقصد تحویل می‌دهد. تنظیمات شبکه و مزایای استفاده از معماری لبه شبکه در کاربردهای مختلف مانند رباتیک در \cite{barzegaran2020fogification} به‌طور مفصل توضیح داده شده است. سیستم‌های رباتیک صنعتی مشابه مبتنی بر مه نیز در \cite{shaik2020fog} و \cite{denzler2020consolidating} پیشنهاد شده‌اند.

معماری‌های مبتنی بر کانتینر در لبه شبکه در \cite{liu2021performance} با توجه به نیازهای صنعتی ارزیابی شده‌اند، و زمان رفت و برگشت، پهنای باند، قابلیت‌های پردازشی و تأخیر هنگام اجرای درخواست‌های یادگیری ماشین برای نگهداری پیش‌بینانه اندازه‌گیری شده است. برای اجرای برنامه‌های کانتینری روی \lr{\tt{Raspberry Pi}} از \lr{\tt{Microsoft Azure IoT Edge}} استفاده شده است. نتایج نشان می‌دهد که کانتینری شدن کارایی را کاهش نمی‌دهد و در عین حال انعطاف‌پذیری و مقیاس‌پذیری را نیز افزایش می‌دهد. در \cite{oyekanlu2017predictive} یک سامانه مدیریت مه برای مدیریت کانتینرهای \lr{\tt{docker}} توسعه داده شده است. برای پایش وضعیت بلادرنگ ماشین‌آلات و انجام نگهداری پیش‌بینانه، یک پایگاه داده ایجاد شده است که به اندازه‌ای کوچک است که بتواند در حافظه دستگاه‌های لبه شبکه جای گیرد و با استفاده از \lr{\tt{Python SQLite}} پیاده‌سازی شده است.

برای یکپارچه‌سازی دیدگاه‌های به‌دست‌آمده از مطالعات مرورشده، در جدول~\ref{table:litr_rev_industry} خلاصه مطالب عنوان شده آمده است. این ترکیب جدولی یک مقایسه ساختاریافته از رویکردهای موجود در پردازش لبه‌ شبکه برای نسل چهارم صنعت را امکان‌پذیر می‌سازد و مسیرهای پژوهشی مشترک، چالش‌های حل‌نشده و شکاف‌های خاصی را که انگیزه‌بخش مشارکت‌های این رساله هستند، برجسته می‌کند

\begin{table}[t]
\center
\caption{مقایسه مقالات پردازش لبه شبکه در نسل چهارم صنعت}
\begin{tabular}{|c|c|c|}
\hline
مقاله & هدف اصلی & حوزه کاربرد\\
\hline
\hline
\cite{vakili2019open} & بهره‌برداری از منابع & کنترل بلادرنگ فشار گاز\\ 
\cite{oyekanlu2017predictive} & بهره‌برداری از منابع & نگهداری پیش‌بینانه \\
\cite{chalapathi2021iioT} & تاخیر و بهره‌وری انرژی & نگهداری فعال \\
\cite{kaur2018edge} & تاخیر و بهره‌وری انرژی & شبکه مبتنی بر نرم‌افزار \\
\cite{kristiani2021cloudedge} & بهره‌وری انرژی و منابع & پایش کیفیت هوا\\
\cite{chen2018edge} & امنیت و تاخیر & نگهداری فعال \\
\cite{okay2016fog} & امنیت و تاخیر & شبکه هوشمند برق\\
\cite{fu2018secure} & امنیت و بهره‌برداری از منابع & پایش دمای کارخانه هوشمند\\
\cite{pop2021fora} & امنیت، تاخیر و بهره‌برداری از منابع & مسیریابی نوار نقاله، نگهداری پیش‌بینانه توزیع‌شده\\
\cite{chekired2018industrial} & امنیت و بهره‌برداری از منابع & شبیه‌سازی با داده واقعی اینترنت اشیاء صنعتی\\
\cite{denzler2020consolidating} & امنیت و بهره‌برداری از منابع & تحلیل داده‌های بلادرنگ ماشین\\
\cite{shaik2020fog} & امنیت و بهره‌برداری از منابع & ربات‌های صنعتی\\
\cite{liang2020edge} & تاخیر و بهره‌برداری از منابع & شبیه‌سازی طبقه‌بندی تصویر\\
\cite{Ferrari2019Anomaly} & تاخیر و بهره‌برداری از منابع & تشخیص بلادرنگ ناهنجاری\\
\cite{Lee2020SmartMfg} & تاخیر و بهره‌برداری از منابع & کارخانه هوشمند\\
\cite{liu2021performance} & تاخیر و بهره‌برداری از منابع & سامانه برای باغ‌های عمودی دیواری\\
\cite{li2018adaptive} & تاخیر، بهره‌وری انرژی و منابع & کارخانه هوشمند\\
\hline
\end{tabular}
\label{table:litr_rev_industry}
\end{table}

\section{رقابت بر سر منابع در پردازش ابری}

مطالعات موجود درباره‌ی تداخل کارایی عمدتاً بر یکی از جنبه‌های زیر متمرکز هستند:
\begin{enumerate}
\item
تحلیل علل تداخل کارایی
\item
روش‌های ارزیابی تداخل کارایی به‌صورت کیفی یا کمی
\item
رویکردهای کاهش یا اجتناب از تداخل کارایی
\end{enumerate}
علمی اصلی از جمله \lr{\tt{IEEEXplore}}، \lr{\tt{Springer}}، \lr{\tt{Elsevier}} و \lr{\tt{ACM Digital Library}} را در این بخش مرور می‌کنیم. \lr{\tt{performance interference}}، \lr{\tt{VM interference}}، \lr{\tt{container interference}}، \lr{\tt{resource contention}}، \lr{\tt{interference in cloud}} و \lr{\tt{interference-aware}} را به‌عنوان کلیدواژه‌ها در عنوان‌ها و چکیده‌ها انتخاب کردیم و نتایج را بر اساس مرتبط بودن موضوع پالایش کردیم.

\subsection{تشخیص تداخل کارایی برنامه‌ها}

انتخاب معیار کارایی، کلید بازتاب دقیق شدت تداخل است. می‌توان وقوع تداخل کارایی را با مشاهده و مقایسه مقادیر چند معیار تحت شرایط ایده‌آل و واقعی ارزیابی کرد. در مقاله \cite{novakovic2013deepdive}، مجموعه‌ای از معیارها را برای دسته‌بندی ماشین‌های مجازی در شرایط ایده‌آل بدون تداخل استفاده کرده است. سپس با خوشه‌بندی، وقوع تداخل کارایی را ارزیابی کرده است. علاوه بر این، \cite{joshi2017sherlock} از روش‌های تشخیص نقاط پرت استفاده کرده است، به‌طوری‌که برنامه‌ای که مقادیر غیرعادی در معیارها نشان می‌دهد، می‌تواند به‌عنوان برنامه‌ای در نظر گرفته شود که توسط سایر برنامه‌ها دچار تداخل شده است.

هر چه دو برنامه از نظر نیاز به منابع شبیه‌تر باشند، تداخل قوی‌تر خواهد بود. بر این اساس، رویکرد شهودی که در \cite{rahimizadeh2021design} مورد توجه قرار گرفته، ‌استفاده از شباهت نیازهای منابع برای ارزیابی هم‌مکانی دو برنامه است. علاوه بر این، مراکز داده ابری معمولاً از تخصیص بیش از حد استفاده می‌کنند تا بهره‌وری منابع را به حداکثر برسانند، که این منجر به این می‌شود که نیازهای منابع توسط برنامه‌های مستقر شده روی سرور از منابع واقعی در اختیار سرور فراتر رود \cite{lang2016overbooking}. به عنوان مثال، تخصیص هسته‌های مجازی \lr{\tt{vCPU}} بیشتر به ماشین‌های مجازی نسبت به تعداد واقعی هسته‌ها، می‌تواند منجر به کمبود هسته‌های پردازشی در دسترس، تداخل و افت کارایی شود.

\subsection{مدل کردن تداخل کارایی برنامه‌ها}

چندین روش برای مدل‌سازی تأثیر عملکرد یک برنامه بر برنامه‌ی هم‌مکان آن وجود دارد. یک مدل، شدت تداخل منابع را در سطوح مختلف سامانه، از برنامه تا کل سامانه خدمات ابری، نشان می‌دهد. برای ارائه‌دهنده خدمات مهم است که عملکرد واقعی سرورهای مجازی خود را قبل از برنامه‌ریزی و اتخاذ هر تصمیم در مورد زمان‌بندی یا مقیاس‌دهی در یک مرکز داده ابری مدل‌سازی و اندازه‌گیری کند. مدلسازی تداخل با اهداف متفاوتی انجام می‌گیرد. اولین هدف، مدل‌سازی ویژگی‌های تداخل یک برنامه یا ماشین مجازی منفرد است و هدف دوم، مدل‌سازی کارایی واقعی یا افت کارایی در حضور تداخل. دو هدف اول برای بهینه‌سازی آگاه از تداخل بر اساس معیارهای یک برنامه یا ماشین مجازی منفرد مفید هستند. سومین نوع اهداف مدل‌سازی، مدل‌سازی در سطح گروه است که در آن تداخل کارایی در یک گروه از ماشین‌های مجازی هنگام مهاجرت یا یک گروه از برنامه‌های رقیب بر سر منابع مشخص بررسی می‌شود. چهارمین هدف مدل‌سازی، مدل‌سازی تداخل از منظر منابع است. چون تداخل کارایی ناشی از رقابت منابع است، مدل‌های مبتنی بر منابع می‌توانند با تخصیص مجدد منبع بحرانی، برای حل مشکل تداخل کارایی به کار گرفته شوند. برخی از کارهای ذکرشده در این بخش در جدول~\ref{table:litr_rev_contention_model} فهرست شده‌اند.

\begin{table}[t]
\center
\caption{مقایسه مقالات مرور شده بر اساس هدف گذاری مدلسازی تداخل کارایی}
\begin{tabular}{|c|c|p{5cm}|p{5cm}|}
\hline
مقاله & هدف مدل & طرح کاربرد & استفاده مدل\\
\hline
\hline
\cite{kim2013vmconsolidation} & مشخصات تداخل & برنامه‌های حافظه-نیاز با اشتراک حافظه پنهان & تعیین مقدار حساسیت به تداخل و شدت ایجاد تداخل \\
\cite{Chen2016Cache} & مشخصات تداخل & ماشین مجازی با نیاز زیاد به حافظه پنهان & تعیین مقدار حساسیت به تداخل و شدت ایجاد تداخل \\
\cite{Bu2013ILA} & کارایی نسبی & عملیات \lr{\tt{MapReduce}} در خوشه & پیش‌بینی کارایی برنامه تحت تداخل \\
\cite{novakovic2013deepdive} & کارایی نسبی & اجرای برنامه تحلیل‌گر زیر تداخل & پیش‌بینی کارایی برنامه تحت تداخل \\
\cite{Peng2018VMProfiling} & منابع بحرانی & هر ماشین مجازی & توصیف تداخل با چهار منبع مورد استفاده ماشین مجازی \\
\cite{koh2007interference} & منابع بحرانی & هر سروری & تعیین منبع مزاحمت اصلی \\
\cite{Xu2014iAware} & مدل گروهی & مهاجرت ماشین مجازی & تعیین میزان تداخل حین مهاجرت ماشین مجازی \\
\cite{Shaw2019Energy} & مدل گروهی & برنامه تعادلی با نیاز تاخیر کم & تعیین تداخل دو برنامه هم‌مکان \\
\hline
\end{tabular}
\label{table:litr_rev_contention_model}
\end{table}

از منظر برنامه‌ها و ماشین‌های مجازی، تداخل کارایی متقابل اما نامتقارن است. برنامه‌ها یا ماشین‌های مجازی مختلف ویژگی‌های تداخل متفاوتی دارند. برخی به ‌راحتی تحت تأثیر قرار می‌گیرند و برخی به ‌راحتی روی نمونه‌های هم‌مکان خود تأثیر می‌گذارند. حساسیت به تداخل معیاری است برای سنجش اینکه یک برنامه یا ماشین مجازی تا چه حد هنگام هم‌مکان شدن با دیگران آسیب می‌بیند، و شدت تداخل معیاری برای سنجش میزان تهاجمی بودن یک برنامه یا ماشین مجازی هنگام استفاده از منابع است. برای مثال، در \cite{kim2013vmconsolidation} ویژگی‌های تداخل بر اساس حافظه پنهان سطح آخر \lr{\tt{LLC}} مشترک و پهنای باند حافظه برنامه‌ها در فضای ابری مدل‌سازی شد. نویسندگان دریافتند که شدت تداخل به دو معیار مرتبط است: نرخ خطای \lr{\tt{LLC}} (تعداد خطاها در ثانیه) و نسبت خطای \lr{\tt{LLC}} (تعداد خطاهای \lr{\tt{LLC}} نسبت به مراجعات \lr{\tt{LLC}}). در \cite{Chen2016Cache} نیز حساسیت و شدت تداخل ماشین‌های مجازی روی منابع حافظه پنهان مورد بررسی قرار گرفت.

تعدادی از مطالعات پیشنهاد کرده‌اند که تداخل را با مقایسه کارایی در شرایط ایده‌آل و شرایط تداخل با معرفی مفهوم امتیاز یا کارایی نرمال‌شده اندازه‌گیری کنند\cite{novakovic2013deepdive, cheng2017precise}، همانطور که در فصل~\ref{chap:pre} در فرمول~\eqref{eq:rel_perf} آورده شد. متریک استفاده شده در فرمول یاده شده می‌توند زمان اجرای برنامه \cite{novakovic2013deepdive, Zhao2016Interference, Chen2017Prophet, Javadi2016UIE}، یا نرخ خروجی\cite{Chiang2011TRACON}، یا کیفیت خدمت \cite{Yang2013BubbleFluxConf} و یا مشخصه‌های سطح پایین سامانه مانند تعداد چرخه پردازنده به ازای دستور \lr{\tt{CPI}} یا تعداد میلیون دستور در ثانیه \lr{\tt{MIPS}} \cite{novakovic2013deepdive, cheng2017precise, Zhang2013CPI2} باشد. همچنین متریک‌های اندازه‌گیری می‌تواند نرخ بهره‌وری پردازنده مجازی \lr{\tt{vCPU}}، چرخه‌های پردازنده و نرخ خطای حافظه پنهان باشد \cite{Sun2014MVEI}. برای برنامه‌های نیازمند به \lr{\tt{I/O}} نرخ خروجی، پهنای باند، تعداد خوانش و نوشتن یا نرخ ارسال انتخاب می‌شود \cite{Casale2011StorageIO}.

تداخل منابع معمولاً زمانی رخ می‌دهد که چندین ماشین مجازی میزبان مشترک از یک نوع خاص از منابع باشند. بنابراین، یک روش عمومی برای تشخیص تداخل کاربار ماشین مجازی، نظارت بر مصرف منابع و سنجش ارتباط آن با تداخل است. \cite{Peng2018VMProfiling} یک نمایه برای یک ماشین مجازی ایجاد کردند که شامل مصرف پردازنده،‌ حافظه، پهنای باند، \lr{\tt{I/O}} است. هر نوع منبع دارای سه معیار است: میانگین بهره‌وری، میانگین بار اجرا شده و نسبت مواقعی که از اجرا موجب عبور از آستانه به مواقع کلی می‌شود. با استفاده از این معیارها، نویسندگان می‌توانند مصرف منابع ماشین مجازی را ارزیابی کرده و سپس تشخیص دهند که آیا بار روی ماشین مجازی باعث تداخل کاربار به دلیل رقابت برای یک منبع خاص شده است یا خیر. آنها تداخل را به سه دسته تقسیم می‌کنند: بدون تداخل، تداخل متوسط و تداخل شدید. \cite{Javadi2017DIAL} از یک دسته‌بند مبتنی بر درخت تصمیم برای شناسایی منبع اصلی تداخل استفاده کردند. آنها یک آزمایش کنترل‌شده تداخل را با استفاده از مجموعه \lr{\tt{MicroBenchmark}} انجام دادند و با داده‌های پایش شده در هر حالت آموزش دادند. پس از آموزش، درخت تصمیم می‌تواند منابع تداخل را بر اساس مشاهدات اندازه‌گیری‌شده، که به‌راحتی قابل مشاهده هستند مانند بهره‌وری \lr{\tt{CPU}} و زمان انتظار \lr{\tt{I/O}}، طبقه‌بندی کند.

مدل‌های مقالات پیشین با پایش سیستم عمل می‌کنند و نمی‌توانند استفاده آینده از منابع را پیش‌بینی کنند. \cite{Barve2019FECBench} از \lr{\tt{Random Forest Regression}} برای پیش‌بینی بهره‌وری منابع برنامه‌ها در طول اجرا استفاده کرده است. آنها زمان اجرای واقعی برنامه را بر اساس استفاده از منابع پیش‌بینی‌شده توسط مدل محاسبه کردند. علاوه بر این، \cite{Chen2015CloudScope} روشی برای پیش‌بینی وضعیت تداخل هر منبع بر اساس زنجیره مارکوف پیشنهاد دادند.

شاخه‌ای از مطالعات موجود بر اندازه‌گیری تداخل کلی عملکرد در سطح کل مرکز داده ابری متمرکز است. در فرآیند مهاجرت ماشین مجازی، تداخل ممکن است به دلیل تعامل بین سرور مبدا، سرور مقصد و ماشین مجازی مورد مهاجرت رخ دهد. بنابراین، تحلیل تداخل عملکرد برای مهاجرت ماشین مجازی باید نه تنها به بهینه‌سازی یک ماشین مجازی یا یک سرور توجه کند، بلکه همه شرکت‌کنندگان در رویداد مهاجرت را نیز باید در نظر بگیرد \cite{Xu2014iAware, Shaw2019Energy}.

\subsection{روش‌های اندازه گیری مزاحمت}

از بررسی مقالات، می‌توان نتیجه گرفت که دو روش برای جمع‌آوری داده‌ها برای مدل‌سازی تداخل وجود دارد: جمع‌آوری داده‌ها بر اساس تزریق تداخل و جمع‌آوری داده‌ها بر اساس سوابق تاریخی.

ایده‌ی پایه‌ی تزریق تداخل این است که فشار روی منابع مشخصی که ماشین مجازی یا برنامه‌ی مورد آزمایش روی آن اجرا می‌شود، افزایش یابد. با کنترل شدت فشار منابع، می‌توان عملکرد واقعی برنامه را در سطوح مختلف تداخل به‌دست آورد و حساسیت آن نسبت به تداخل را مشخص کرد. دو روش برای اعمال فشار روی منابع وجود دارد: یکی افزایش ساده‌ی کاربار روی ماشین میزبان و دیگری شبیه‌سازی تداخل منابع با کنترل دستی ظرفیت منابع است \cite{Taheri2017vmBBProfiler}. نمونه‌هایی از کاربارهای \lr{\tt{Benchmark}} شامل \lr{\tt{iBench}}\cite{Delimitrou2013iBench}، \lr{\tt{CISBench}}\cite{Mars2011CrossCore} و \lr{\tt{Cuanta}}\cite{Govindan2011Cuanta} هستند. بار تزریق‌شده نمی‌تواند به‌طور دقیق میزان اشغال منابع خود را کنترل کند؛ بنابراین، پژوهشگران عملکرد واقعی بار مورد آزمایش را در شرایط مختلف تداخل با اجرای هم‌زمان بار مورد آزمایش همراه با تعداد زیادی برنامه‌ی مختلف به‌دست می‌آورند، مانند \cite{Barve2019FECBench} این برنامه‌ها را در دسته‌های مختلف طبقه‌بندی کرده و سپس قانون کلی عملکرد تجمعی بارهای مورد آزمایش هم‌زمان با انواع مختلف وظایف را خلاصه کرده‌اند.

در سوابق تاریخی، داده‌های لازم برای ایجاد مدل تداخل را می‌توان مستقیماً از لاگ‌های یک سامانه ابری استخراج کرد. به‌دلیل ماهیت پویای محیط ابری، عملکرد کاربارها و ماشین‌های مجازی در حال اجرا در طول زمان تا حدی نوسان خواهد داشت و این داده‌ها در داده‌های پایشی ثبت می‌شوند. پژوهشگران می‌توانند از ابزارهایی برای جمع‌آوری داده‌های تاریخی استفاده کنند. برای مثال، \cite{Masouros2021Rusty} از PCM API برای جمع‌آوری شمارنده‌های عملکرد پایه استفاده کردند و \cite{buchaca2020seq2seq} با استفاده از فراخوانی‌های سیستمی داده‌های مرتبط را جمع‌آوری کردند. البته پژوهشگران می‌توانند داده‌های مورد نیاز مدل را مستقیماً از مجموعه داده‌های متن باز استخراج کنند و به این ترتیب نیازی به اجرای ماشین مجازی ندارند که باعث صرفه‌جویی در مصرف منابع و زمان می‌شود. داده‌های جمع‌آوری‌شده از سوابق تاریخی می‌تواند ارزشمندتر از داده‌های به‌دست‌آمده در محیط آزمایشی باشد، اما برخی محدودیت‌ها را نیز داراست. اول، انعطاف‌پذیری کم است؛ اگر نیاز باشد پایش منابع به‌روزرسانی شود، داده‌های تاریخی باید دوباره جمع‌آوری شوند. دوم، دامنه کاربرد آن فقط برای خوشه‌هایی با تداخل منابع زیاد مناسب است، در حالی که برای خوشه‌ای با محیط عملیاتی پایدار، به‌دلیل نبود تداخل کافی، نمی‌توان داده‌های جامع تداخل عملکرد را به‌دست آورد.

روش‌های مدل‌سازی موجود در مقالات معمولاً در دو دسته قرار می‌گیرند: مدل‌سازی تحلیل کیفی و مدل‌سازی تحلیل کمی. خروجی مدل‌سازی تحلیل کیفی، وجود یا سطح تداخل عملکرد و خروجی تحلیل کمی، مقداری است که درجه تداخل عملکرد را اندازه‌گیری می‌کند.

\subsubsection{روش‌های کیفی اندازه گیری مزاحمت}

بیشتر کارهای موجود از روش‌های طبقه‌بندی یا خوشه‌بندی برای تحلیل کیفی استفاده کرده‌اند. ما این مقالات را در جدول~\ref{table:litr_rev_quality_anal} خلاصه و مقایسه کرده‌ایم.

\begin{table}[t]
\center
\caption{مقایسه مقالات مرور شده بر اساس تحلیل کیفی}
\begin{tabular}{|c|c|p{8cm}|}
\hline
مقاله & روش تحلیل & نتیجه تحلیل\\
\hline
\hline
\cite{kim2013vmconsolidation} & طبقه‌بندی \lr{\tt{SVM}} و خوشه بندی \lr{\tt{K-means}} & دسته‌بندی بر اساس شدت نیاز به هر منبع و اعلام شدت تداخل بر اساس کم، معمولی و زیاد \\
\cite{Shaw2019Energy} & طبقه‌بندی \lr{\tt{ANN}} & دسته‌بندی بر اساس تعاملی یا حساس به تاخیر بودن \\
\cite{Ludwig2019affinity} & طبقه‌بندی ایستا & دسته‌بندی بر اساس کم، متوسط یا زیاد بودن تداخل\\
\cite{koh2007interference} & خوشه‌بندی سلسله‌مراتبی & دسته‌بندی برنامه‌های شناخته شده و استفاده برای برنامه‌های ناشناخته\\
\cite{li2020dccpi} & خوشه‌بندی سلسله‌مراتبی & گروه‌بندی برنامه‌ها بر اساس تداخل عملکرد در خوشه\\
\hline
\end{tabular}
\label{table:litr_rev_quality_anal}
\end{table}

در خوشه‌بندی سطح تداخل دسته‌بندی می‌شود. برای مثال \cite{kim2013vmconsolidation} با کمک \lr{\tt{K-means}} داده تداخل را در سطوح مختلف دسته‌بندی می‌کند. در \cite{li2020dccpi} با کمک خوشه‌بندی سلسله‌مراتبی شباهت بین برنامه‌های ناشناخته و شناخته را بررسی و به کمک آن تداخل برنامه ناشناخته را تقریب می‌زند.

\subsubsection{روش‌های کمی اندازه گیری مزاحمت}

هدف از ساخت مدل‌های تحلیل کمی، سنجش شدت تداخل است. فرآیند مدل‌سازی در این روش، ایجاد رابطهٔ بین متریک مستقل انتخاب‌شده و متریک‌های سنجش تداخل کارایی است. ما برخی از مطالعات انجام شده را در جدول~\ref{table:litr_rev_quantity_anal} خلاصه کرده‌ایم.

\begin{table}[t]
\center
\caption{مقایسه مقالات مرور شده بر اساس تحلیل کمی}
\begin{tabular}{|c|c|p{3cm}|p{7cm}|}
\hline
مقاله & روش تحلیل & منابع تداخل & نتیجه تحلیل \\
\hline
\hline
\cite{Anu2019IALM} & تحلیل آماری & شبکه و پردازنده & کمی‌سازی افت کارایی ناشی از مزاحمت مهاجرت ماشین مجازی \\
\cite{wang2015vmon} & تحلیل آماری & شبکه و پردازنده & کمی‌سازی افت کارایی ناشی از هم‌مکانی ماشین‌های مجازی با پردازش بالا یا دسترسی زیاد به شبکه \\
\cite{jersak2016performance} & تابع رگرسیون & پردازنده، حافظه و فضای ذخیره‌سازی & رابطه بین تعداد ماشین مجازی با تداخل \\
\cite{Javadi2016UIE} & تابع رگرسیون & پردازنده و فضای ذخیره‌سازی & کمی‌سازی افت کارایی ناشی از ۴ متریک مرتبط با پردازنده و فضای ذخیره‌سازی \\
\cite{Chen2015CloudScope} & زنجیره مارکوف & شبکه، پردازنده و فضای ذخیره‌سازی & پیش‌بینی افت کارایی ناشی از تداخل \\
\cite{gan2019seer} & شبکه عصبی & همه منابع & پیش‌بینی تداخل دو برنامه بر اساس شبکه عصبی بازگشتی \\
\cite{Masouros2021Rusty} & شبکه عصبی & همه منابع & پیش‌بینی تداخل دو برنامه بر اساس شبکه عصبی \lr{\tt{LSTM}} \\
\hline
\end{tabular}
\label{table:litr_rev_quantity_anal}
\end{table}

در تحلیل آماری همبستگی بین متغیرهای مستقل و معیارهای تداخل را بررسی می‌کنند، مانند روابط متناسب و معکوس. برای مثال، \cite{Anu2019IALM} بر این باور است که تداخل کارایی در فرآیند مهاجرت عمدتاً ناشی از منابع \lr{\tt{CPU}} و منابع شبکه است. تداخل ناشی از منابع \lr{\tt{CPU}} به‌صورت رابطه~\eqref{eq:rel_res_contention} بیان می‌شود:

\begin{equation} \label{eq:rel_res_contention}
    M_c = \frac{C_d}{C_l}
\end{equation}

که در آن $M_c$ نشان‌دهنده درجه رقابت منابع پردازنده است. $C_d$ تعداد پردازنده‌های مورد نیاز ماشین مجازی در سامانه و $C_l$ تعداد کل پردازنده‌هایی است که می‌توان به آن‌ها تخصیص داد.

هدف مدل تابع رگرسیون، توصیف رابطهٔ نگاشت بین یک یا چند متغیر نشان‌دهندهٔ کارایی و معیار سنجش تداخل کارایی است. \cite{jersak2016performance} از روش رگرسیون برای برقراری رابطه بین تعداد ماشین‌های مجازی هم‌مکان و درجهٔ تداخل کارایی در عملیات هم‌مکانی بارهای سنگین تک منبع، استفاده کرده است.

\subsection{برنامه‌ریزی آگاه به تداخل}

بیشتر مطالعاتی که با هدف جلوگیری یا کاهش تداخل کارایی ماشین‌های مجازی انجام شده‌اند، بر بهینه‌سازی مکان‌یابی و تجمیع ماشین‌های مجازی تمرکز دارند. راهبردهای مکان‌یابی آگاه از تداخل، تخصیص را بهینه می‌کنند تا در مرحلهٔ اولیهٔ برنامه‌ریزی، از تأثیر بالقوهٔ تداخل کارایی بر ماشین‌های مجازی جدید (و وظایف مرتبط با آن‌ها) جلوگیری شود. اکثر این روش‌ها به دنبال جلوگیری یا کاهش تداخل کارایی از طریق کاهش رقابت بر سر منابع هستند. این مطالعات در جدول~\ref{table:litr_rev_schedule} خلاصه شده‌ است.

انتخاب سروری که درخواست در آن برنامه‌ریزی شود، به اهداف بهینه‌سازی مکان‌یابی بستگی دارد. اهداف را می‌توان به دو دسته تقسیم کرد. یکی کاهش تداخل برای درخواست برنامه‌ریزی شده و دیگری تضمین بهینه بودن کارایی کل سامانه است. برای هدف نخست، در برخی مقالات، تداخل پیش‌بینی‌شده در فرآیند جستجوی سرور مقایسه می‌شود و سروری انتخاب می‌شود که اگر درخواست به آن تخصیص داده شود، کمترین تداخل کارایی را به همراه داشته باشد \cite{zhang2015minimizing,romero2018mage}. علاوه بر این، برخی پژوهش‌ها به دنبال کمینه‌سازی تداخل نیستند، بلکه کافی است تداخل از آستانه فراتر نرود \cite{Bu2013ILA, jersak2016performance, angelou2016improving} یا تاخیر پاسخ به درخواست از مهلت مقرر عبور نکند \cite{Chen2017Prophet}. برای هدف دوم، الگوریتم باید تداخل کلی در سطح گروهی میان تمام موجودیت‌های ابری مرتبط را در نظر بگیرد. برخی تحقیقات مدل‌های تداخل کارایی هر یک از موجودیت‌های منفرد مانند ماشین‌های مجازی یا وظایف را ترکیب کرده و یک مدل کلی تداخل کارایی ایجاد کردند \cite{meloalves2018interference, hamdi2019managing, lin2012interference}، و برخی دیگر مستقیماً از مدل کلی ساخته‌شده در مرحلهٔ مدل‌سازی استفاده کردند \cite{Shaw2019Energy}.

\begin{table}[t]
\center
\caption{مقایسه مقالات مرور شده حوزه برنامه‌ریزی تداخل}
\begin{tabular}{|c|p{3cm}|p{6cm}|p{4cm}|}
\hline
مقاله & منبع تداخل & هدف مکان‌یابی & قانون مکان‌یابی \\
\hline
\hline
\cite{Chiang2011TRACON} & پردازنده و فضای ذخیره‌سازی & مکان‌یابی درخواست ورودی با کمینه کردن تداخل برنامه‌های هم‌مکان & روش اکتشافی \\
\cite{jersak2016performance} & مموری، پردازنده و فضای ذخیره‌سازی & مکان‌یابی درخواست ورودی با قیود ظرفیت منابع و آستانه تداخل & روش اکتشافی \\
\cite{sampaio2015piasa} & پردازنده و شبکه & رعایت قیود کارایی درخواست و نیازمندی منابع & روش اکتشافی \\
\cite{meloalves2018interference} & پردازنده و شبکه & کمینه‌سازی زمان اجرای درخواست و سرورهای فعال & فرا اکتشافی و برنامه‌نویسی عدد صحیح \\
\cite{hamdi2019managing} & مموری، پردازنده و فضای ذخیره‌سازی & بهینه‌سازی تعداد سرورهای فعال، بهره‌برداری از منابع و زمان اجرای درخواست‌ها & فرا اکتشافی و برنامه‌نویسی عدد صحیح \\
\hline
\end{tabular}
\label{table:litr_rev_schedule}
\end{table}

به دلیل محیط پویا در مراکز دادهٔ ابری، میزبان اولیهٔ یک ماشین مجازی ممکن است پس از مدتی، مناسب‌ترین میزبان برای آن درخواست نباشد. استراتژی‌های تثبیت طراحی شده‌اند تا مکان ماشین‌های مجازی را به‌صورت پویا تنظیم کنند. بهینه‌سازی تثبیت ماشین‌های مجازی آگاه از تداخل با هدف تنظیم نگاشت فعلی ماشین مجازی به سرور انجام می‌شود تا از تأثیر تداخل کارایی در سامانه جلوگیری یا آن را کاهش دهد. اگر آستانهٔ رقابت منابع فراتر رود، کارایی کاهش‌یافته ناشی از تداخل، غیرقابل قبول تلقی شده و اجرای استراتژی تثبیت فعال می‌شود \cite{Zhang2013CPI2, zhu2012performance}. ما مطالعات مرتبط را در جدول~\ref{table:litr_rev_consolidation} خلاصه کرده‌ایم.

\begin{table}[t]
\center
\caption{مقایسه مقالات مرور شده حوزه تثبیت ماشین مجازی}
\begin{tabular}{|c|R{3cm}|p{5cm}|p{5cm}|}
\hline
مقاله & عملیات & معیار & راهبرد \\
\hline
\hline
\cite{novakovic2013deepdive} & مهاجرت برخط & انحراف شدید متریک‌های ماشین مجازی از مقدار نرمال & مهاجرت ماشین‌های مجازی متاثر با قید تعداد بسیار کم، وگرنه مهاجرت عاملان تداخل \\
\cite{wang2015vmon} & مهاجرت برخط & عبور افت کارایی از آستانه & همانند \cite{novakovic2013deepdive} \\
\cite{ahn2012dynamic} & مهاجرت برخط & نرخ بالای خطای حافظه پنهان برای ماشین مجازی و سرور & مهاجرت ماشین مجازی با نرخ خطای \lr{\tt{LLC}} بالا به سرور با نرخ خطای \lr{\tt{LLC}} پایین \\
\cite{salimi2013batch} & خاموش کردن ماشین مجازی & اختلال عملکرد ماشین مجازی برای دیگر ماشین‌های مجازی & ماشین مجازی تداخلگر معلق می‌شود \\
\cite{Zhang2013CPI2} & خاموش کردن ماشین مجازی & نوسان غیرعادی چرخه به ازای دستور & ماشین مجازی خرابکار خاموش می‌شود \\
\cite{nishtala2020twig} & مهاجرت برخط & قضاوت \lr{\tt{Q-learning}} برای تغییر وضعیت & پاداش کیفیت خدمت در سامانه چند عاملی \lr{\tt{Q-learning}} \\
\hline
\end{tabular}
\label{table:litr_rev_consolidation}
\end{table}

\subsection{تشخیص و پیش‌بینی تداخل برای برنامه‌های کانتینر محور}

عمده توجه مقالات در سال‌های گذشته بیشتر معطوف به تداخل ماشین‌های مجازی یا برنامه‌های کاربردی بدون مجازی‌سازی بوده است. تعداد مقالاتی که به تداخل کانتینرها توجه کرده‌اند محدودتر است. تحلیل تداخل عملکرد کاربارهای کانتینری هم‌مکان و ساخت مدل برای شناسایی و پیش‌بینی تداخل عملکرد برای کانتینر، پژوهش‌های ارزشمندی هستند. \cite{chen2020interference} از روش مشاهده مستقیم برای تحلیل تداخل هم‌مکان کاربارهای مختلف کانتینری در سطح ریزمعماری استفاده کرد (مثلاً شمارنده‌های سخت‌افزاری، نرخ خواندن و نوشتن، و زمان اجرا در محیط‌های هم‌مکان مختلف). همچنین فهرستی از کاربارهای هم‌مکان پیشنهادی و غیرپیشنهادی برای انواع مختلف برنامه‌های کانتینری ارائه داد. در \cite{medel2023modeling} اندازه‌گیری‌های سطح پایین همانند مشخصه‌های حافظه پنهان و پردازنده انجام گرفته و سپس با ترکیب نسبی مشخصه‌ها، معیارهای سطح بالا توصیف تداخل پیشنهاد شده است. سپس برای مدلسازی تداخل از تابع رگرسیون استفاده و با اجرای هم‌مکان برنامه مورد نظر در کنار کانتینرهای \lr{\tt{Benchmark}} تداخل را بر اساس معیارها فرموله می‌کند. با داشتن مدل تداخل هر برنامه، می‌تواند تداخل آن را با یک برنامه دیگر که معیارهای آن در اجرای تنها اندازه‌گیری شده است پیش‌بینی کند. اما مدل آن تنها قادر به پیش‌بینی تداخل بین دو کانتینر است. در \cite{Kaur2020KEIDS} توصیف تداخل به صورت کیفی بیان شده و برای جلوگیری از تداخل از قانون نزدیکی استفاده می‌کند. طبق این قانون برنامه‌هایی که در مصرف یک منبع رفتار شدیدی دارند، هم‌مکان نمی‌شوند.

\section{رویکرد پژوهش در پوشش شکاف‌های تحقیقاتی}

برای رفع محدودیت‌های ذکر شده، پژوهش حاضر مدل‌سازی تداخل چندبرنامه‌ای را در محیط‌های \lr{\tt{MEC}} نسل چهارم صنعت به‌ویژه برای کاربارهای حساس به تأخیر ارائه می‌دهد. این رویکرد شکاف تحقیقاتی در کاربردهای محاسبات لبه شبکه و همچنین زمان‌بندی آگاه از تداخل در محیط‌های ابری را پر می‌کند و چارچوبی جامع برای مدیریت منابع آگاه از عملکرد در استقرارهای صنعتی \lr{\tt{MEC}} ارائه می‌دهد.